<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Flask 上下文]]></title>
    <url>%2F2018%2F02%2F05%2Fcontext%2F</url>
    <content type="text"><![CDATA[在 Flask 中有个 context 即上下文的概念。一直不是很理解，今天查阅了多方资料，有了一个基础的认识。简单的总结一下  上下文概念 上下文的原文是 context，简单的理解上下文的含义是指：在处理一个请求的时候所要包含的前提条件（及后续条件）。比如我们需要在每次请求之前要知道的数据库连接信息，所在的应用信息，用户的请求信息等。  Flask中的上下文对象RequestContent 请求上下文 Request 请求的对象，会封装每次的 Http 请求 (environ) 的内容； Session 会根据请求中的 cookie，重新载入该访问者相关的会话信息。 AppContext 应用上下文 g 处理请求时用作临时存储的对象，每次请求都会重设这个变量；作为一个请求内的全局变量，可以在用于在装饰器 before_request() 、 after_request() 和 teardown_request() 中保存变量信息。 在0.10之后它可以作用于整个应用。 current_app 当前激活的应用，在多应用时候可以准确的定位到目前所用的app。 生命周期 current_app 的生命周期最长，只要当前实例还在运行中，它就不会失效。 g 和 Request 的生命周期都是一个请求的周期。一个请求结束后，其生命周期也结束了。 session的生命周期取决于它是否过期用户是否关闭浏览器等，跟普通的 session 生命周期一样。 创建模式 Flask 启动时会有两种状态，开始的状态可以做些应用级的初始化；当第一个请求过来之后，就进入了另外的一个状态，具体请参考官方文档。 应用上下文 在应用上下文中，包括了 current_app、g 两个对象，一般来说，该对象有如下的两种创建方式： 在处理请求的时候会自动创建； 通过 app_context() 手动创建，通常用在一些单元测试的场景中。 官方文档中文介绍 请求上下文 在请求上下文中，包含了 request 、 session 两个对象，同样有如下两种创建方式： 在处理请求的时候自动创建 通过app.test_request_context(‘/route?param=value’)手动创建。需要注意的是，如果创建请求上下文时候，当前没有应用上下文，则会自动创建应用上下文。也就是说请求上下文一定是在应用上下文存在的基础上存在的。 官方文档中文介绍 线程安全 在处理 request 请求的时候，在线程或协程环境下，各线程是如何有条不紊的调用自己的变量的。 flask 中的线程安全在 Python 中的线程安全机制是 treadin.local(), 而 flask 中的线程安全机制是使用werkzeug中的Local 实现的。除了线程，它还支持协程。 flask 中定义在 flask 中，上下文的定义存在于 globals.py 中。 LocalProxy 和 LocalStackLocalProxy 和 LocalStack 都是werkzeug中定义的。LocalProxy 是一个代理对象，它能够把接收到的请求转发给本地的local 对象，而LocalStack 则是一个模拟了堆栈实现保存与线程相关的变量，使不同线程的变量不会混淆。 上下文源码上下文相关的源码在 ctx.py 中。 参考文章: 本文章更详细的叙述了有关上下文的源码及实现原理]]></content>
      <tags>
        <tag>Flask</tag>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[git 命令记录]]></title>
    <url>%2F2018%2F01%2F02%2Fgit%2F</url>
    <content type="text"><![CDATA[本文作为记录在使用 git 时候遇到的问题及解决方案。持续更新。 使用 http or https 方式时记住用户名密码 git config credential.helper store]]></content>
      <tags>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[财务报表初版总结]]></title>
    <url>%2F2018%2F01%2F02%2Ffinancial%2F</url>
    <content type="text"><![CDATA[财务报表项目v1版本已上线，在此总结下。  项目简介财务报表是财务对于当天的支出收入信息进行汇总给财务总监审核，审核通过后给 Boss 看的一个报表。 项目前端分为 pc 端和 手机微信端，微信端是接入到企业号的应用，对于后端而言，没有多大区别。 根据用户不同分的权限也不同：财务员工：录入，提交审核。财务总监：审核，审核通过 or 驳回重新录入。Boss：查看（财务总监审核通过的）报表。 项目工作项目采用 Django + SQLAlchemy 数据库用的 MySQL 本来这样的一个小项目，可以用更轻量级的 Flask 或者刚好练练手 sanic 的，但是当时比较急，就用了比较快捷及比较熟悉些的 Django。现在看来选型并不是很成功，尤其是其间 SQLAlchemy 遇到了一些坑。但是Django的确更省事。如果有时间可以考虑重构一下。 相关：对数据进行加密存库接口采用 RESTful API风格 及 token 认证 部署：supervisor + gunicorn + nginx 日志：logbook 实现方式认证管理用户首次登录会以 cookie （微信端） 或者 json （pc 端） 形式返回用户 token ，用户带着 token 请求接口，如 token 过期或者认证失败将会返回401。 权限管理不同身份有不同的权限， 在 user 表中添加一个身份字段，不同值代表不同身份。 wechat 网页授权登录 企业微信开发者文档 一个标准的OAuth2认证模式。 因为微信端有身份判断，所以需要获取到当前登录的用户信息。根据开发者文档，除了需要传一些必要的字段之外，需要传一个 redirect url 也就是 授权成功后的跳转页面 和 state 字段（自定义值）。 微信授权后直接带着code 字段及传入的 state 值 （拼接在 url 中返回）去请求 redirect url，而要获取用户信息的话需要这个 code 字段和 access token 。 也就是说我们需要拿到这个 code。 这里我们跟前端的处理方式是这样的：1&gt; 前端传一个redirect url 到后端wechat-login 接口2&gt; 后端记录 redirect url 并为其生成一个 uuid 作为对应关系保存于数据库。3&gt; 后端将用 uuid 和一个新的redirect url （即后端的wechat-auth 接口）拼接为 wechat 的认证url。4&gt; wechat 返回新的带有 state 和 code 的 url 请求wechat-auth 接口，在 wechat-auth 接口中获取 code 值及 uuid 对应的原前端要重定向的 url，根据 code 获取用户信息，放到 cookie 中重定向到前端要重定向的 url。也就是说，最后在后端完成重定向，重定向到前端想要去的页面，重定向到的页面可以从 cookie 中获得后端设置的用户信息。 ps: Django 中设置 cookie 及重定向 12345from django.http import HttpResponseRedirectres = HttpResponseRedirect(res_url)res.set_cookie("COOKIE_TOKEN_KEY", "xxx")res.set_cookie("COOKIE_USER_KEY","xxxx")return res 加密MySQL 有一套加密方式，示例： 123insert into users(test) values(AES_ENCRYPT('teststr','salt'))； select AES_DECRYPT(test,'salt') from users； 相对应的 SQLAlchemy 也可以加密，而且加密后为二进制需要转换为十六进制存储使用 SQLAlchemy 时用 func 然后使用相应的函数就可以了。16进制转换： func.hex func.unhex加解密：func.aes_encrypt(value, key)func.aes_decrypt(value, key) SQLAlchemy 遇到的问题SQLAlchemy 遇到了很多坑，因为之前只是用 SQLAlchemy 写一些脚本，真正用到 web 项目很少， 这次又是强行放到 Django 上，所以因为不够熟悉所以出了一些问题。 主要问题： 1.问题描述： 一个接口报错后，全部接口都不能用了，主要是因为一个接口报错后，它就停留在报错的事务，没有进行手动回滚，所以导致其它的接口都没办法工作了。 解决方案：try catch 到异常后 进行 rollback 。这样解决了一个报错其他都不能用的问题，但是弊端是无法显式的看到报错，只能在日志中查看报错信息。 2.问题描述每天早晨来到公司后发现 连接断开了，造成这种情况的原因可能是：1&gt; 数据库重启了，导致连接池断开。因为在测试环境所以不太稳定。2&gt; 连接池连接的空闲时间超过（配置时间），断开了。 总之就是因为连接池断开后没有自动重连导致的，从网上搜了下解决方案，暂时解决了问题。 解决方案： 禁用SQLAlchemy提供的数据库连接池，只需要在调用create_engine是指定连接池为NullPool，SQLAlchemy就会在执行session.close()后立刻断开数据库连接 create_engine()函数和连接池相关的参数有:-pool_recycle, 默认为-1, 推荐设置为7200, 即如果connection空闲了7200秒, 自动重新获取, 以防止connection被db server关闭.-pool_size=5, 连接数大小，默认为5，正式环境该数值太小，需根据实际情况调大-max_overflow=10, 超出pool_size后可允许的最大连接数，默认为10, 这10个连接在使用过后, 不放在pool中, 而是被真正关闭的.-pool_timeout=30, 获取连接的超时阈值, 默认为30秒 参考： 这位小兄弟的博客中的这篇连接池的介绍 连接池的问题，感觉自己理解的还是不够到位，还需要进一步学习。暂时就这些，如果有需要补充的再次补充。]]></content>
      <tags>
        <tag>project</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[xcode 引发的报错]]></title>
    <url>%2F2017%2F12%2F05%2Fclang%2F</url>
    <content type="text"><![CDATA[我在mac 上面用 pip 安装的时候，有时候会遇到报错。在一堆血红的报错上面，有一句这样的话： verror: command ‘clang’ failed with exit status 1 这时候就是xcode出了问题：一行命令解决： xcode-select –install 安完之后， 再 pip 就没问题了。]]></content>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[高性能 MySQL 笔记之一 事务]]></title>
    <url>%2F2017%2F11%2F28%2Fmvcc%2F</url>
    <content type="text"><![CDATA[最近在抽时间看《高性能 MySQL》这本书，顺便做下笔记。 Mysql 事务介绍事务：一组原子性sql操作。特点：要么全执行，要么全部执行失败。一个良好的事务所要具备四个标准的特性：ACID 特性：原子性（atomicity）： 一个事物必须是不可分割的最小单元， 对于一个事务来说，要么全部执行成功，要么全部执行失败，不可能只执行其中一部分。这就是事务的原子性。一致性（consistency）：事务总是从一个一致的状态转到另一个一致的状态，不可能只改变其中一部分，也还是必须全部一起改变状态。隔离性（isolation）：通常来说， 一个事务在执行时对其他事务是不可见的，也就是说是一个独立的存在。具体特殊情况特殊分析，具体参考其隔离级别。持久性（durability）：一旦事务提交，数据将会永久保存到数据库中。 ACID 说起来容易，但是真的支持这一特性，数据库需要很复杂的实现，相比于不支持 ACID的数据库要耗费更多的资源。如果是不需要事务类的应用场景，选用不支持事务的数据库可以获得更高的性能。 隔离级别四种隔离级别： READ UNCOMMITED 未提交读事务中的修改，在没有提交之前可以被读，这样容易造成脏读，简单来说，脏读就是，在一个事务请求数据库，但是还没提交的时候，另一个请求用了此数据，这样就造成了脏读。通常，未提交读会造成很多问题，而且并不会提高太多性能，所以一般不推荐使用此隔离级别。 READ COMMITTED 提交读 MySQL 是开启自动提交的，如果要测试可以关闭自动提交，手动 commit。show variables like ‘autocommit’set autocommit = 0 一个事务在提交之前对其它事务不可见，也就是说一个事务执行时候只对已经提交的数据进行操作。这一级别也叫做 不重复读，也就是说：两次执行同样的操作，读取的数据可能是不同的。 举例： A 客户端操作1select value from table where id = 1 得到结果 1这时我们 A 客户端并未提交 这时候如果我们用 B 客户端 修改 id=1的值并且提交：12update table set value=10 where id = 1commit; 这时候再用 A 客户端 取 id =1 的值 得到的会是10。这就是不可重复读带来的问题，两次同样的 sql 读取结果可能会出现不一致的情况。 REPEATABLE READ 可重复读可重复读避免了不可重复读的问题，也避免了脏读问题，但是同时也带来了新的问题：幻读。幻读：幻读指当用户读取某一范围的数据行时，另一个事务又在该范围内插入了新行，当用户再读取该范围的数据行时，会发现有新的“幻影”行。 mysql默认的隔离级别就是 REPEATABLE READ 可重复读 SERIALIZABLE 可串行化 SERIALIABLE是最高的隔离级别，通过强制事务串执行，避免了幻读问题。简单来说，SERIALIABLE 会在每一行数据上加锁，所以可能导致大量的超时和锁征用问题，实际中很少用到此级别，只有对数据一致性要求极高的情况下才会使用。 隔离级别示意图 隔离级别 脏读可能性 不可重复读可能性 幻读可能性 加锁读 READ UNCOMMITTED ✔ ✔ ✔ ✘ READ COMMITTED ✘ ✔ ✔ ✘ REPEATABLE READ ✘ ✘ ✔ ✘ SERIALIZALBE ✘ ✘ ✘ ✔ 死锁死锁是指两个或多个事务在同一资源上互相占用，并请求锁定对方所占用的资源，从而导致恶性循环的情况。死锁发生时候要完全或者部分回滚其中一个事务才能打破死锁。死锁就是两个人迎面过独木桥，只有其中一个人返回才能打破僵局。 关于锁，在 mysql 中有基本的共享锁（读锁）和排它锁（写锁），当然你也可以手动加锁，但是并不推荐，除非你关闭了自动提交。如果不关闭自动提交加锁会导致事务和锁造成@#￥%……&amp;，会发生啥我也不知道，总之不可预知，不要尝试。 事务日志事务日志可以帮助提高事务的效率，使用事务日志，存储引擎在修改表的数据时候只需要修改其内存拷贝，再把修改记录持久到硬盘日志中，不用每次将数据直接持久化到磁盘，事务日志采用追加的方式，顺序 I/O，所以效率很高。事务日志可以在后台慢慢刷回磁盘中，所以采用事务日志效率相对较高。目前大多数存储引擎都是这样实现的，我们通常称之为预写式日志，修改数据需要写两次磁盘。如果数据的修改已经持久化到硬盘，但是还没写到磁盘。若中途发生意外重启，恢复后硬盘数据会恢复，具体恢复机制视搜索引擎而定。 MVCC 多版本并发控制我们看到了简单的行级锁存在诸多限制，大多数的搜索引擎实现的都不是简单的行级锁，基于提高并发性能考虑，他们一般都实现了MVCC 即多版本并发控制。因为 MVCC 并没有一个标准，所以不同的数据库的实现方式也不同。MVCC 是通过保存某一个时刻的快照来实现的，也就是说，不同时间点执行的同样操作，结果可能是不同的。以 InnoDB 为例，InnoDB 的 MVCC 通过保存后面两个隐藏列：开始时间（开始版本号），结束时间（结束版本号）。但是并不是存的真的时间，而是自增的版本号。 SELECTa.查找版本早于当前事务版本号数据行，这样可以保证数据是之前插入过的或者是事务本身插入的。b.行的删除版本号要么晚于当前版本号，要么未定义，这样可以确保读取到的数据在事务开始之前未被删除。INSERT为新插入的每一行保存当前系统号作为行版本号。DELETE 为删除的每一行保存当前系统版本号作为删除标志。UPDATE保存当前系统版本号为版本号，同时保存当前系统版本号到原来的行作为删除标志。 这两个版本号，可以使大多数操作不用加锁，操作简单，提高了性能，不足之处是每行记录都需要额外的空间，需要更多的行检查工作。MVCC 只在REPEATABLE 和 READ COMMITTED 两个隔离级别下工作。其他两个隔离级别和 MVCC 都不兼容。因为 READ UNCOMMITTED 总是读取到最新的数据行而不是符合当前事务版本的数据行。而 SERIALIZABLE 则会对所有读取的行都加锁。]]></content>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mysql触发器trigger使用]]></title>
    <url>%2F2017%2F11%2F20%2Ftrigger%2F</url>
    <content type="text"><![CDATA[简介trigger 是 mysql 中的一个触发器，触发器的主要作用是在执行 mysql 之前或者之后来执行一些特定的操作。 操作规则主要针对的 mysql 操作：insert、update、delete。 触发的时间设定是： before （sql 执行前）、after（sql 执行之后）。 示例示例语句12345CREATE triggername AFTER INSERT ON tablename FOR EACH ROW BEGIN DECLARE CONTINUE HANDLER FOR SQLEXCEPTION BEGIN END; SELECT OLD.id FROM tablename;END; 示例含义创建一个 名为triggername的触发器，在tablename表插入数据之后执行，查找原有的 id，作用于每一行操作。 并且忽略掉触发器的 sql 错误，也就是触发器与原sql 互不影响。 示例详解1CREATE triggername 创建一个 名为triggername的触发器。 12AFTER INSERT ON tablename 在 insert 之后 执行， 这里我们也可以用 BEFOR ，在insert之前，同时操作类型也支持 update 和 delete。也就是 AFTER|BEFORE INSERT|DELETE|UPDATE 并作用于 tablename 这张表 12BEGIN DECLARE CONTINUE HANDLER FOR SQLEXCEPTION BEGIN END; 开始一系列操作的语句，通常我们要执行一组sql 的时候 会用到 begin end 语法。 声明 trigger 和其作用到的 sql 语句互相独立。因为对于 trigger 而言 ，所要执行的 sql 语句和 trigger 相当于是在同一个事务内。也就是说 sql 执行成功则执行 trigger 。同理若 trigger 执行失败了，则原sql也不会成功执行，会进行回滚。有时候 trigger 是在业务已经完善之后要加的一些操作，为了避免影响到原有的 sql 执行，所以加了这一声明，来忽视 trigger可能遇到的的错误。若 sql 执行成功，trigger 执行不成功的时候，自动忽略trigger 内的错误。不要影响到原有 sql。DECLARE 具体写法参考：参考地址 12SELECT OLD.id FROM tablename; END; 执行要触发的语句 这里是查找出原有 sql 的 id 。如果是打印执行后的 id 则是 NEW.id。这里用 OLD 和 NEW 分别表示执行前和执行后的状态。 结束执行语句 删除 trigger1DROP TRIGGER triggername; 注意事项如果是在 sql 命令行执行的话， 注意执行语句前要先执行 DELIMITER // 因为 sql语句是以 ; 分隔的。而DELIMITER主要是将复合的sql语句作为一条语句一次性执行。]]></content>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[简单的笔记]]></title>
    <url>%2F2017%2F11%2F18%2Fnote%2F</url>
    <content type="text"><![CDATA[brew 简单操作命令 安装 vim： brew install vim查看 brew 可升级应用：brew outdated查看 brew 安装的应用版本： brew list —versionsbrew 安装的文件默认安装到/usr/local/bin/下设置 brew 安装的 vim 为默认vim:alias vim=’/usr/local/bin/vim’ Windows 查看进程详情 原问题是 想看不同的 Python.exe 运行的是具体哪个脚本。在任务管理器加一列。Command Line。 zsh 配置文件 之前在 bash_profile 中修改了环境变量 但是 总是不生效 需要每次都 source 一下因为 bash_profile 是 bash 的配置文件,修改了下 zsh 的配置文件,让 zsh 加载 bash的配置文件就好了vim ~/.zshrc加上:source ~/.bash_profile就可以了 mac 强制退出 command + Option + Esc 设置服务器免密登录 ssh-copy-id -p [port] [username]@[host]执行完此步之后会让你输入密码 输入后即可把自己的公钥上传到服务器 实现免密登录 查看端口号 列出进程 id lsof -i:8000 查询文件所在的位置 find / -name filename git 撤销提交 git reset HEAD^git push origin dev -f mongodb 导入导出数据 导入数据mongorestore -h 127.0.0.1:27017 -d 数据库名字 文件地址 导出数据mongodump -h IP -port 端口 -u 用户名 -p 密码 -d 数据库 -o 文件存在路径]]></content>
      <tags>
        <tag>shell</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[The first article]]></title>
    <url>%2F2017%2F11%2F16%2Ffirst%2F</url>
    <content type="text"><![CDATA[1print ("hello world") 之前搭建过一个 blog，主要是看着好看，实用性并不好。 后来在 csdn 记录，再后来就很少记录了，有一些需要记录的都记在 Notion 或者有道云笔记。 记在本地笔记的坏处是 总是记得很随意，而写博客能对细碎的知识点重新梳理一下。 工作之余，用 Hexo + NexT 搭建了这个博客，简介而又功能齐全。 很久没有写一些随笔感悟之类，社交平台的繁杂导致越來越不愿意表达自己。 以后有随笔感悟也可以写在这里，反正也没几个人看的。=_= 不会说话了，就这样吧。 希望能坚持。]]></content>
      <tags>
        <tag>others</tag>
      </tags>
  </entry>
</search>
